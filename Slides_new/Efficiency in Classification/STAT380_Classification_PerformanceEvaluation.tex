\documentclass[compress]{beamer}
\mode<presentation>
\setbeamercovered{transparent}
\usetheme{Warsaw}
%\useoutertheme{smoothtree}
\usepackage{multirow}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{xmpmulti}
\usepackage{multicol}
\usepackage{colortbl}

%\setbeamersize{text margin left=.25 in,text margin right=.25 in}
\setbeamersize{text margin left=.15 in,text margin right=.15 in}
\usepackage[authoryear]{natbib}


\usepackage{epstopdf}
\usepackage{xcolor}
\usepackage{latexcolors}
%\usepackage[dvipsnames]{xcolor}
\definecolor{antiquebrass}{rgb}{0.8, 0.58, 0.46}
\definecolor{babyblueeyes}{rgb}{0.63, 0.79, 0.95}
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{bistre}{rgb}{0.24, 0.17, 0.12}
\definecolor{brightlavender}{rgb}{0.75, 0.58, 0.89}
\definecolor{bulgarianrose}{rgb}{0.28, 0.02, 0.03}
\definecolor{slateblue}{rgb}{0.56, 0.74, 0.56}
\definecolor{cordovan}{rgb}{0.54, 0.25, 0.27}
\definecolor{darkbyzantium}{rgb}{0.36, 0.22, 0.33}

\setbeamercolor{structure}{fg=camouflagegreen!90, bg= black!60}







\usepackage{tikz}
\usetikzlibrary{shadows,calc}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes.symbols}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{multirow}
%%%%%%%%% shaddow image %%%%%
% some parameters for customization
\def\shadowshift{3pt,-3pt}
\def\shadowradius{6pt}
\colorlet{innercolor}{black!60}
\colorlet{outercolor}{gray!05}
% this draws a shadow under a rectangle node
\newcommand\drawshadow[1]{
\begin{pgfonlayer}{shadow}
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.south west)+(\shadowshift)+(\shadowradius/2,\shadowradius/2)$) circle (\shadowradius);
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.north west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$) circle (\shadowradius);
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.south east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$) circle (\shadowradius);
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.north east)+(\shadowshift)+(-\shadowradius/2,-\shadowradius/2)$) circle (\shadowradius);
    \shade[top color=innercolor,bottom color=outercolor] ($(#1.south west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$) rectangle ($(#1.south east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$);
    \shade[left color=innercolor,right color=outercolor] ($(#1.south east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$) rectangle ($(#1.north east)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$);
    \shade[bottom color=innercolor,top color=outercolor] ($(#1.north west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$) rectangle ($(#1.north east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$);
    \shade[outercolor,right color=innercolor,left color=outercolor] ($(#1.south west)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$) rectangle ($(#1.north west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$);
    \shade[outercolor,right color=innercolor,left color=innercolor] ($(#1.north west)+(-\shadowradius/12,\shadowradius/12)$) rectangle ($(#1.south east)+(\shadowradius/12,-\shadowradius/12)$);%Frame
    \filldraw ($(#1.south west)+(\shadowshift)+(\shadowradius/2,\shadowradius/2)$) rectangle ($(#1.north east)+(\shadowshift)-(\shadowradius/2,\shadowradius/2)$);
\end{pgfonlayer}
}
% create a shadow layer, so that we don't need to worry about overdrawing other things
\pgfdeclarelayer{shadow} 
\pgfsetlayers{shadow,main}
% Define image shadow command
\newcommand\shadowimage[2][]{%
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[#1]{#2}};
\drawshadow{image}
\end{tikzpicture}}
\usepackage{calligra}

\DeclareMathOperator*{\argmax}{Arg\,max}
\DeclareMathOperator*{\argmin}{Arg\,min}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert }
\newcommand{\bbetaHat}{ \widehat{\bbeta}}
\newcommand{\bbetaLSE}{ \widehat{\bbeta}_{_{\text{LSE}}}}
\newcommand{\bbetaMLE}{ \widehat{\bbeta}_{_{\text{MLE}}}}
\newcommand{\sqBullet}[1]{  {\tiny \tiny \tiny \qBoxCol{#1!60}{ }} }
%***************
%\newtheorem{thm}{Theorem}
\input{definition_include.tex}
\input{BoxDef}
\input{MatrixDef}











\title{  STAT 380:\\ {\color{black} Classification Technique:   Evaluating  Performance of a Classification Technique}}

\author[UAEU]
{UAEU}
\institute[IIM] % (optional, but mostly needed)
{
  \inst{}%
  %Indian Institute of Management,  Udaipur\\
  \vspace{0.1in}

  
}

\date{}


\newcommand{\Xnew}{ \HLTEQ[orange]{X_{_{\text{i}}}} }
\newcommand{\Ynew}{ \HLTEQ[orange]{Y_{_{\text{i}}}} }

%\date{\today}

\AtBeginSection[]
{
  \begin{frame}{Inhalt}
 % \begin{multicols}{1}
	\frametitle{Outline}
    \tableofcontents[currentsection]
  %  \end{multicols}
  \end{frame}
}

\begin{document}
\maketitle





\begin{frame}{Outlook of the unit}
	
	\begin{itemize}
		\item \textbf{Prediction and Classification Approaches}
		\vspace{0.2cm}
	\begin{itemize}

		\item Classification Techniques
			\begin{itemize}
			\item Logistic regression
				\vspace{0.2cm}
			\item Discriminant analysis
					\end{itemize}
			\vspace{0.2cm}
			\item {\bf \color{airforceblue}  Evaluating  Performance of a Classification Technique}
				\vspace{0.2cm}
			\item Tree-based methods: Decision trees
				\vspace{0.2cm}
				\begin{itemize}
				\item Classification trees
				\vspace{0.2cm}
				\item
				Regression trees
	\end{itemize}
		\end{itemize}
		\end{itemize}		
\end{frame}


\TransitionFrame[antiquebrass]{\Large  Evaluating  Performance of a Classification Technique}

\begin{frame}
	\frametitle{ }
	\begin{itemize}
\item[ ] \qbx[4.1in]{purple!40}{\sqBullet{purple}A natural criterion for judging the performance of a classifier is the probability
of making a \textbf{misclassification} error.}
			\vspace{0.2cm}
		\item[]  \qbx[4.1in]{teal!40}{ \sqBullet{teal}Misclassification means that the record
belongs to one class but the model classifies it as a member of a different class..}
			\vspace{0.2cm}
		\item[ ] \qbx[4.1in]{apricot!40}{\sqBullet{brown} Is there a minimal
probability of misclassification that we should require of a classifier?}
	
			\vspace{0.2cm}
		\item[ ] \qbx[4.1in]{amber!40}{\sqBullet{amber} A classifier that makes no errors would be perfect - unrealistic.}
	
		
	\end{itemize}
\end{frame}






\begin{frame}
	\frametitle{}
	\begin{itemize}
  \item Classification matrix summarizes the correct and incorrect classifications
that a classifier produced.
  \item Rows and columns
of the confusion matrix correspond to the predicted and true (actual) classes.
\item Example:\\[-2mm]
\begin{tabular}{cccc}

  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
 &  & \multicolumn{2}{|l}{Actual class} \\
  & & \multicolumn{1}{|c}{0} & 1 \\\hline
\multirow{2}{*}{Predicted class} & 0 & \multicolumn{1}{|c}{2600} & 100 \\
 & 1 & \multicolumn{1}{|c}{100} & 200 \\
\end{tabular}
\item Diagonal cells give the number of
correct classifications.
\item Off-diagonal cells give counts of misclassification.
\item Classification matrix gives estimates of the true classification and misclassification
rates.
\end{itemize}
\end{frame}






\begin{frame}
	\frametitle{}
	\begin{itemize}
  \item Classification matrix summarizes the correct and incorrect classifications
that a classifier produced.
  \item Rows and columns
of the confusion matrix correspond to the predicted and true (actual) classes.
\item Example:\\[-2mm]
\begin{tabular}{cccc}

  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
 &  & \multicolumn{2}{|l}{Actual class} \\
  & & \multicolumn{1}{|c}{0} & 1 \\\hline
\multirow{2}{*}{Predicted class} & 0 & \multicolumn{1}{|c}{2600} & 100 \\
 & 1 & \multicolumn{1}{|c}{100} & 200 \\
\end{tabular}
\item Diagonal cells give the number of
correct classifications.
\item Off-diagonal cells give counts of misclassification.
\item Classification matrix gives estimates of the true classification and misclassification
rates.
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Accuracy measures - the classification matrix}
\begin{itemize}
\item We summarize the classification for the validation data as follows.
\item \textbf{Classification matrix}:\\[-2mm]
\begin{center}
\begin{tabular}{cccc}

  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
 &  & \multicolumn{2}{|l}{Actual class} \\
  & & \multicolumn{1}{|c}{$C_1$} & $C_2$ \\\hline
\multirow{1}{*}{Predicted} & $C_1$ & \multicolumn{1}{|c}{$n_{1,1}$} & $n_{2,1}$\\
class & $C_2$ & \multicolumn{1}{|c}{$n_{1,2}$} & $n_{2,2}$ \\
\end{tabular}
\end{center}
\item Estimated \textbf{misclassification rate}: $$err=\frac{n_{1,2}+n_{2,1}}{n_v},$$ where $n_v$ is the total number of units in the validation data.
\item \textbf{Estimated accuracy}: $$accuarcy = 1- err=\frac{n_{1,1}+n_{1,1}}{n_v}.$$
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Propensities and cut-off for classification}
\begin{itemize}
  \item First step in most classification algorithms is to estimate the probability $\pi$ (propensity) that
a unit belongs to each of the classes.
  \item If overall classification accuracy is of interest, the
unit can be assigned to the class with the highest probability.
  \item In many records,
a single class is of special interest, so we will focus on that particular class.
  \item It may make sense in such cases to consolidate classes so that you end up
with two: the class of interest and all other classes.
\item The default \textbf{cutoff} value in two-class classifiers is 0.5.
\item It is possible, however, to use a cutoff that is either higher or
lower than 0.5. Two examples:
\begin{itemize}\item[-] unequal misclassification costs \item[-] unequal importance of classes.
\end{itemize}
\end{itemize}
\end{frame}




\begin{frame}	\frametitle{Evaluation Metrics}

 \qbx[4.5in]{amber!40}{ 
 \includegraphics[scale=.35]{ClassificationMatrix.png}
 }
 \vspace{.5in}
\end{frame}


\begin{frame}
	\frametitle{Evaluation Metrics (1)}
	General form of a $2\times2$ confusion matrix
	
	\vspace{0.3cm} 
	
	\noindent
	\renewcommand\arraystretch{1.5}
	\setlength\tabcolsep{0pt}
	\begin{tabular}{|c >{}r| @{\hspace{0.7em}}|c |@{\hspace{0.4em}}c 
			|@{\hspace{0.7em}}l}
		\multirow{8}{*}{\parbox{1.7cm}{\bfseries\raggedleft Predicted\\ value}} & 
		& \multicolumn{2}{c}{\bfseries Actual value} & \\
		& & $C_1$ &  $C_2$ &   Row total \\
		& $C_1^{'}$ & \bf{True}{Positive} & \bf{False}{Positive} & P$'$ 
		\\[2.4em]
		& $C_2^{'}$ & \bf{False}{Negative} & \bf{True}{Negative} & N$'$ \\
		& Column total & P & N &
	\end{tabular}
	
	\vspace{0.5cm}
	
	\small{Note: $C_1$ is assumed to correspond to a positive class}
\end{frame}



\begin{frame}
	\frametitle{Predictive measures derived from a confusion matrix:}
	

	% \qbx[4.5in]{purple!40}{ 
	\qBrd[3in]{blue!30}{
	  $$   \text{\bf{	Accuracy:}}\frac{TP + TN}{TP + TN + FP + FN}$$
	  } \\\vspace{0.1in}
	 % }
	   \qBrd[3in]{asparagus!30}{
	  $$ \textbf{Error rate} : 1 - Accuracy$$
	  } \\\vspace{0.1in}
	    \qBrd[3in]{wisteria!40}{
	  $$\textbf{Sensitivity}:    \frac{TP}{TP + FN}$$
	  } 
	  \\\vspace{0.1in}
	    \qBrd[3in]{wheat!40}{
	  $$\textbf{Specificity}:   \frac{TN}{TN + FP}$$
	  } 


\end{frame}



\begin{frame}\frametitle{Specificity and Sensitivity }
 \qBrd[4.5in]{purple!40}{ \sqBullet{purple}
Sensitivity and specificity are statistical measures of the performance of a binary classification test. }\\
\vspace{0.1in}
 \qBrd[4.5in]{apricot!40}{ \sqBullet{apricot}
Sensitivity(true positive rate) measures the proportion of actual positives which are correctly identified.}
\\
\vspace{0.1in}
 \qBrd[4.5in]{brass!40}{ \sqBullet{brass}
Specificity (true negative rate) measures the proportion of negatives that are correctly identified.}




\end{frame}




\begin{frame}\frametitle{Specificity and Sensitivity }
 \qbx[4.5in]{wisteria!40}{ \sqBullet{wisteria}
{\bf Sensitivity: } Ability of a test to identify those who have disease
The sensitivity of a test is the probability of a positive test result given the presence of the disease, $P(Test=+\mid Diseased)=\frac{a}{a+c}$
}\\\vspace{.1in}
 \qbx[4.5in]{apricot!70}{ \sqBullet{brown}
{\bf Specificity:}  Ability of a test to exclude those who don't have   the   disease The specificity of a test is the probability of a negative test result given the absence of the disease,$P(Test=-\mid Not Diseased)=\frac{d}{b+d}$
}





\end{frame}




\begin{frame}	\frametitle{Sensitivity and Specificity }

 \qbx[4.5in]{wisteria!40}{ 
  \begin{center}
 \includegraphics[scale=.32]{SensitivitySpecificity.png}
 \end{center}
 }
 \vspace{.5in}
\end{frame}

\begin{frame}\frametitle{Receiver Operating Characteristic (ROC)}
\qBrd[4.5in]{uclablue!30}{The \textbf{R}eceiver \textbf{O}perating \textbf{C}haracteristic (ROC) curve is a way to visualize 
	interrelationship between sensitivity and specificity
	}\\\vspace{.1in}
 \qbx[4.5in]{antiquefuchsia!40}{ \sqBullet{antiquefuchsia}
In a ROC curve the true positive rate (Sensitivity) is plotted as function of the false positive rate (100-Specificity) for different cut-off points.
 Each point on the ROC curve represents a (sensitivity, specificity) pair corresponding to a specific decision threshold. }\\
 \vspace{.1in}
 \qbx[4.5in]{armygreen!40}{ \sqBullet{armygreen}
A test with perfect discrimination (no overlap in the two distributions) has a ROC curve that passes through the upper left corner (100\% sensitivity, 100\% specificity). }\\
 \vspace{.1in}
 \qbx[4.5in]{amethyst!40}{ \sqBullet{amethyst}
Therefore, the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test.}

\end{frame}

\begin{frame}\frametitle{ROC}
 \qbx[4.5in]{amethyst!40}{
 \begin{center}
\includegraphics[scale=.3]{ROC.png}
\end{center}
}

\end{frame}


\begin{frame}
 \qBrd[4.5in]{armygreen!40}{ \sqBullet{armygreen}
If $0.7 \leq  AUC < 0.8$, this is considered acceptable discrimination. }\\
\vspace{.1in}
 \qBrd[4.5in]{amethyst!40}{ \sqBullet{amethyst}
If $0.8 \leq AUC < 0.9$, this is considered excellent discrimination. }\\
\vspace{.1in}
 \qBrd[4.5in]{purple!40}{ \sqBullet{purple}
If $0.9 \leq  AUC$, this is considered outstanding discrimination. }

\vspace{.3in}
\qbx[4.5in]{olive!50}{\sqBullet{olive}AUC (area under curve) indicates model goodness, 1 being a perfect model 
	and below 0.5 (yellow line) a useless model (worse then a coin flip).
	}
\end{frame}


%\begin{frame}
%	\frametitle{ROC Curve}
%	
%	The \textbf{R}eceiver \textbf{O}perating \textbf{C}haracteristic (ROC) curve is a way to visualize 
%	interrelationship between sensitivity and specificity
%	
%		\begin{figure}
%			\centering
%			%\includegraphics[width=0.47\textwidth]{Grafiken/ROC}
%			%\caption{}
%			\label{fig:ROC}
%		\end{figure}
%	
%	AUC (area under curve) indicates model goodness, 1 being a perfect model 
%	and below 0.5 (yellow line) a useless model (worse then a coin flip).
%	
%	
%\end{frame}



\begin{frame}\frametitle{Youden Index}


\end{frame}

\end{document}
